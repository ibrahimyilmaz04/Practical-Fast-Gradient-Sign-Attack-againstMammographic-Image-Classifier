# On the Assessment of Robustness of Telemedicine Applications against Adversarial Machine Learning Attacks

In this project, I aimed to show if there are adversarial attacks that can fool mammographicimage classifiers. Based on my study, it is found that mammographic image classifiers might misclassify the input images if they are poisoned by adversarial attacks. As a result, the robustness of the breast cancer classifiermodel will be impacted. I addressed issue by showing different case studies and analyzed a potential solution for this problem. This project contains the following constructive contributions to highlight this security weakness and heighten awareness of physicians when giving a diagnosis of cancer.

- I highlighted and assessed the security vulnerability of CNN, which are widely used in the diagnosis of breast cancer.
- I implemented an efficient adversarial attack on mammographic images in order to fool the mammographic image classifier.
- I analyzed the comparison between original and crafted mamograpgic images using structural similarity index (SSIM) and investigate how originalimage changes based on different perturbation coefficient.
